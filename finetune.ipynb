{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import datetime\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.layers.normalization import *\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune_model(input_shape):\n",
    "    input_tensor = Input(input_shape)\n",
    "    # x = Dropout(0.5)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20787, 4608)\n",
      "(20787, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "X_train = []\n",
    "X_valid = []\n",
    "\n",
    "file_features = [\n",
    "    \"features/finetune_ResNet50BN_160.h5\",\n",
    "    \"features/finetune_VGG16BN_15.h5\",\n",
    "    \"features/finetune_InceptionV3BN_200.h5\"\n",
    "]\n",
    "\n",
    "for filename in file_features:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_valid.append(np.array(h['valid']))\n",
    "        y_train = np.array(h['label'])\n",
    "        y_valid = np.array(h['valid_label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_valid = np.concatenate(X_valid, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "y_train = np.eye(10)[y_train]\n",
    "X_valid, y_valid = shuffle(X_valid, y_valid)\n",
    "y_valid = np.eye(10)[y_valid]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "Train on 20787 samples, validate on 1637 samples\n",
      "Epoch 1/10\n",
      "20787/20787 [==============================] - 1s - loss: 0.0691 - acc: 0.9810 - val_loss: 0.7547 - val_acc: 0.7795\n",
      "Epoch 2/10\n",
      "20787/20787 [==============================] - 1s - loss: 0.0025 - acc: 0.9999 - val_loss: 0.8399 - val_acc: 0.7685\n",
      "Epoch 3/10\n",
      "20787/20787 [==============================] - 1s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9450 - val_acc: 0.7611\n",
      "Epoch 4/10\n",
      "20787/20787 [==============================] - 1s - loss: 8.0202e-04 - acc: 1.0000 - val_loss: 0.9784 - val_acc: 0.7605\n",
      "Epoch 5/10\n",
      "20787/20787 [==============================] - 1s - loss: 5.7662e-04 - acc: 1.0000 - val_loss: 0.9874 - val_acc: 0.7630\n",
      "Epoch 6/10\n",
      "20787/20787 [==============================] - 1s - loss: 4.3883e-04 - acc: 1.0000 - val_loss: 0.9897 - val_acc: 0.7660\n",
      "Epoch 7/10\n",
      "20787/20787 [==============================] - 1s - loss: 3.3620e-04 - acc: 1.0000 - val_loss: 1.0005 - val_acc: 0.7691\n",
      "Epoch 8/10\n",
      "20787/20787 [==============================] - 1s - loss: 2.9367e-04 - acc: 1.0000 - val_loss: 1.0004 - val_acc: 0.7721\n",
      "Epoch 9/10\n",
      "20787/20787 [==============================] - 1s - loss: 2.3383e-04 - acc: 1.0000 - val_loss: 1.0042 - val_acc: 0.7758\n",
      "Epoch 10/10\n",
      "20787/20787 [==============================] - 1s - loss: 1.8172e-04 - acc: 1.0000 - val_loss: 1.0252 - val_acc: 0.7734\n",
      "model save successed\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape):\n",
    "\n",
    "    input_tensor = Input(input_shape)\n",
    "    x = input_tensor\n",
    "    # x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "    model = Model(input_tensor, x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_merged = make_model(X_train.shape[1:])\n",
    "\n",
    "\n",
    "print(\"Adam\")\n",
    "model_merged.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_merged.fit(X_train, y_train, batch_size=batch_size, epochs=10, validation_data=(X_valid,y_valid))\n",
    "model_merged.save(\"models/mixed-model.h5\")\n",
    "print(\"model save successed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def gen_kaggle_csv(model, X_test,  model_image_size, csv_name):\n",
    "    dir = \"dataset\"\n",
    "    y_pred = model.predict(X_test, verbose=1)\n",
    "    print(y_pred[:3])\n",
    "    y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "    print()\n",
    "    print(y_pred[:3])\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    test_generator = gen.flow_from_directory(dir + \"/to_prediction/\", (model_image_size, model_image_size), shuffle=False, \n",
    "                                             batch_size=16, class_mode=None)\n",
    "\n",
    "    l = list()\n",
    "    for i, fname in enumerate(test_generator.filenames):\n",
    "        name = fname[fname.rfind('/')+1:]\n",
    "        l.append( [name, y_pred[i]] )\n",
    "\n",
    "    l = np.array(l)\n",
    "    data = {'img': l[:,0]}\n",
    "    for i in range(10):\n",
    "        data[\"c%d\"%i] = l[:,i+1]\n",
    "    df = pd.DataFrame(data, columns=['img'] + ['c%d'%i for i in range(10)])\n",
    "    df.head(10)\n",
    "    df = df.sort_values(by='img')\n",
    "    df.to_csv(csv_name, index=None, float_format='%.3f')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(MODEL, X_test, image_size, batch_size):\n",
    "    y_pred = MODEL.predict(X_test, verbose=1)\n",
    "    # y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "    \n",
    "    gen = ImageDataGenerator()\n",
    "    path_test_data = 'dataset/to_prediction'\n",
    "    test_generator = gen.flow_from_directory(path_test_data,image_size, shuffle=False, \n",
    "                                             batch_size=batch_size, class_mode=None)\n",
    "    \n",
    "    test_id = list()\n",
    "    for i, file_name in enumerate(test_generator.filenames):\n",
    "        flbase = os.path.basename(file_name)\n",
    "        test_id.append(flbase)        \n",
    "    \n",
    "    return y_pred, test_id\n",
    "\n",
    "def create_submission(predictions, test_id):\n",
    "    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3',\n",
    "                                                 'c4', 'c5', 'c6', 'c7',\n",
    "                                                 'c8', 'c9'])\n",
    "    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n",
    "    now = datetime.datetime.now()\n",
    "    if not os.path.isdir('subm'):\n",
    "        os.mkdir('subm')\n",
    "    suffix = str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n",
    "    result1.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79712/79726 [============================>.] - ETA: 0sFound 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_features = [\n",
    "     \"features/finetune_test_VGG16_BN15.h5\",\n",
    "    \"features/finetune_test_ResNet50_BN160.h5\",\n",
    "    \"features/finetune_test_InceptionV3BN_200.h5\"\n",
    "]\n",
    "X_test = []\n",
    "for filename in test_features:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_test.append(np.array(h['test']))\n",
    "        \n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "predictions, test_id = make_predictions(model_merged, X_test, (299, 299), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission(predictions, test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlnd-dl]",
   "language": "python",
   "name": "conda-env-mlnd-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
