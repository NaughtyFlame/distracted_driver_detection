{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import datetime\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.layers.normalization import *\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune_model(input_shape):\n",
    "    input_tensor = Input(input_shape)\n",
    "    # x = Dropout(0.5)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(input_tensor, x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20787, 6144)\n",
      "(20787, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "X_train = []\n",
    "X_valid = []\n",
    "\n",
    "file_features = [\n",
    "    \"features/finetune_ResNet50.h5\",\n",
    "    \"features/finetune_InceptionV3.h5\",\n",
    "    \"features/finetune_InceptionV3BN_200.h5\"\n",
    "]\n",
    "\n",
    "for filename in file_features:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_valid.append(np.array(h['valid']))\n",
    "        y_train = np.array(h['label'])\n",
    "        y_valid = np.array(h['valid_label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_valid = np.concatenate(X_valid, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "y_train = np.eye(10)[y_train]\n",
    "X_valid, y_valid = shuffle(X_valid, y_valid)\n",
    "y_valid = np.eye(10)[y_valid]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n",
      "Train on 20787 samples, validate on 1637 samples\n",
      "Epoch 1/10\n",
      "20787/20787 [==============================] - 1s - loss: 0.0579 - acc: 0.9852 - val_loss: 0.6787 - val_acc: 0.7856\n",
      "Epoch 2/10\n",
      "20787/20787 [==============================] - 1s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.7492 - val_acc: 0.7660\n",
      "Epoch 3/10\n",
      "20787/20787 [==============================] - 1s - loss: 0.0054 - acc: 0.9990 - val_loss: 0.8307 - val_acc: 0.7685\n",
      "Epoch 4/10\n",
      "20787/20787 [==============================] - 1s - loss: 0.0040 - acc: 0.9993 - val_loss: 0.8535 - val_acc: 0.7648\n",
      "Epoch 5/10\n",
      "20787/20787 [==============================] - 1s - loss: 0.0024 - acc: 0.9997 - val_loss: 0.9794 - val_acc: 0.7502\n",
      "Epoch 6/10\n",
      "20787/20787 [==============================] - 1s - loss: 0.0019 - acc: 0.9998 - val_loss: 0.9052 - val_acc: 0.7654\n",
      "Epoch 7/10\n",
      "20787/20787 [==============================] - 1s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9686 - val_acc: 0.7605\n",
      "Epoch 8/10\n",
      "20787/20787 [==============================] - 1s - loss: 9.3777e-04 - acc: 1.0000 - val_loss: 0.9239 - val_acc: 0.7685\n",
      "Epoch 9/10\n",
      "20787/20787 [==============================] - 1s - loss: 8.8583e-04 - acc: 1.0000 - val_loss: 0.9785 - val_acc: 0.7593\n",
      "Epoch 10/10\n",
      "20787/20787 [==============================] - 1s - loss: 0.0010 - acc: 0.9998 - val_loss: 0.9310 - val_acc: 0.7715\n",
      "model save successed\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape):\n",
    "\n",
    "    input_tensor = Input(input_shape)\n",
    "    x = input_tensor\n",
    "    # x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(10, activation='softmax')(x)\n",
    "    model = Model(input_tensor, x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_merged = make_model(X_train.shape[1:])\n",
    "\n",
    "\n",
    "print(\"Adam\")\n",
    "model_merged.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_merged.fit(X_train, y_train, batch_size=batch_size, epochs=10, validation_data=(X_valid,y_valid))\n",
    "model_merged.save(\"models/mixed-model.h5\")\n",
    "print(\"model save successed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(MODEL, X_test, image_size, batch_size):\n",
    "    y_pred = MODEL.predict(X_test, verbose=1)\n",
    "    y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "    \n",
    "    gen = ImageDataGenerator()\n",
    "    path_test_data = 'dataset/to_prediction'\n",
    "    test_generator = gen.flow_from_directory(path_test_data,image_size, shuffle=False, \n",
    "                                             batch_size=batch_size, class_mode=None)\n",
    "    \n",
    "    test_id = list()\n",
    "    for i, file_name in enumerate(test_generator.filenames):\n",
    "        flbase = os.path.basename(file_name)\n",
    "        test_id.append(flbase)        \n",
    "    \n",
    "    return y_pred, test_id\n",
    "\n",
    "def create_submission(predictions, test_id):\n",
    "    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3',\n",
    "                                                 'c4', 'c5', 'c6', 'c7',\n",
    "                                                 'c8', 'c9'])\n",
    "    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n",
    "    now = datetime.datetime.now()\n",
    "    if not os.path.isdir('subm'):\n",
    "        os.mkdir('subm')\n",
    "    suffix = str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n",
    "    result1.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79392/79726 [============================>.] - ETA: 0sFound 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_features = [\n",
    "     \"features/finetune_test_ResNet50.h5\",\n",
    "    \"features/finetune_test_Xception.h5\",\n",
    "    \"features/finetune_test_InceptionV3.h5\"\n",
    "]\n",
    "X_test = []\n",
    "for filename in test_features:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_test.append(np.array(h['test']))\n",
    "        \n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "predictions, test_id = make_predictions(model_merged, X_test, (299, 299), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission(predictions, test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlnd-dl]",
   "language": "python",
   "name": "conda-env-mlnd-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
